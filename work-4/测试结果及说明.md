# 测试结果及说明

- 919106840212 周运莲
- 第四次机器学习作业：SVM

----



#### 1.首先，调用sklearn中的svm，采用线性核函数进行拟合

<img src=".\img\image-20211215013151792.png" alt="image-20211215013151792" style="zoom: 67%;" />

#### 2.然后作图画出，并且调用cross_val_score进行交叉验证，将80个数据分成了8组，一组十个。

<img src=".\img\image-20211215013321013.png" alt="image-20211215013321013" style="zoom: 50%;" />

#### 3.最终结果为：

<img src=".\img\image-20211215013008975.png" alt="image-20211215013008975" style="zoom:67%;" />

<img src=".\img\image-20211215012857076.png" alt="image-20211215012857076" style="zoom: 50%;" />

说明，在作图时，选取的是最后结果中的第一个支持向量和最后一个支持向量，所以并没有呈现对称分布，理论上我认为应该是正确的。

<img src=".\img\image-20211215013818516.png" alt="image-20211215013818516" style="zoom: 67%;" />

#### 4.与Logistic的比较：

在第二次作业中，分别用SGD和GD实现了Logistic，结果如下：（蓝线：采用批量梯度下降橙线：采用随机梯度下降）

<img src=".\img\image-20211215014142249.png" alt="image-20211215014142249" style="zoom:50%;" />

因为数据量本身比较少，所以从图上来看直观感觉二者结果都比较好。

通过课堂学习和查阅相关网络资料，从理论角度对二者进行比较：

- 　相同点：Logistic和SVM都是分类算法，如果不考虑使用核函数，Logistic和SVM都是线性分类模型，也就是说它们的分类决策面是线性的。通过查阅网络资料发现，其实Logistic也能使用核函数，但我们通常不会在Logistic中使用核函数，只会在SVM中使用。并且Logistic和SVM都是监督学习方法。

- ​    不同点：

  - 二者损失函数不一样，Logistic基于概率理论，通过极大似然估计方法估计出参数的值，然后计算分类概率，取概率较大的作为分类结果。SVM基于几何间隔最大化，把最大几何间隔面作为最优分类面。

  - SVM只考虑分类面附近的局部的点，即支持向量，Logistic则考虑所有的点，与分类面距离较远的点对结果也起作用，虽然作用较小。

  -  SVM中的分类面是由支持向量控制的，非支持向量对结果不会产生任何影响。Logistic中的分类面则是由全部样本共同决定。线性SVM不直接依赖于数据分布，分类平面不受一类点影响；Logistic则受所有数据点的影响，如果数据不同类别strongly unbalance，一般需要先对数据做balancing。